{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary : using a surrogate to show how the homeostasis recovers from a deviation to equiprobability. Little nb_quant, slower decrease of coeffs. Homeostasis should work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=6, suppress=True, threshold=np.inf)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Learning a good dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matname = '2017-05-30_surrogate_DEBUG'\n",
    "DEBUG_DOWNSCALE, verbose = 10, 10\n",
    "matname = '2017-05-30_surrogate'\n",
    "DEBUG_DOWNSCALE, verbose = 1, 10\n",
    "\n",
    "do_sym = False\n",
    "C = 4\n",
    "n_dictionary = 18**2\n",
    "nb_quant = 512\n",
    "\n",
    "\n",
    "N_image = 10000//DEBUG_DOWNSCALE\n",
    "database = '../../2017-02-07_UnsupervisedLearning/database'\n",
    "l0_sparseness = 10\n",
    "N_boost=n_dictionary//2 \n",
    "K_boost = 4.\n",
    "rho_coeff = .9\n",
    "do_plots = True\n",
    "i_sample = 13\n",
    "\n",
    "eta_homeo = .001*DEBUG_DOWNSCALE\n",
    "n_step = 1000//DEBUG_DOWNSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache found /tmp/data_cache/2017-05-30_surrogate_data: Extracting data... Extracting data..Mdn_land53.jpg, Fda_urb540.jpg, Bda_art1079.jpg, Fda_A223013.jpg, Fdn_land317.jpg, Mdn_land750.jpg, Hdn_text6.jpg, Mdn_natu169.jpg, Mdn_N228077.jpg, Hda_obj96.jpg, Fdn_natu815.jpg, Bdn_natu5.jpg, Bdn_land861.jpg, Hda_obj416.jpg, Mdn_nat367.jpg, Bdn_text1.jpg, Mdn_N347004.jpg, Hdn_objn217.jpg, Fdn_land951.jpg, Bda_art1271.jpg, Fdn_natu176.jpg, Mdn_for72.jpg, Hda_obj414.jpg, Mda_urb324.jpg, Hda_obj296.jpg, Bda_int211.jpg, Mda_enc30.jpg, Hda_obj293.jpg, Hdn_N115088.jpg, Bdn_land376.jpg, Bdn_text5.jpg, Hdn_objn180.jpg, Fdn_open13.jpg, Hdn_N124065.jpg, Fda_art1180.jpg, Fda_art1464.jpg, Bda_art145.jpg, Fda_A463059.jpg, Fdn_nat895.jpg, Bda_art621.jpg, Hdn_objn200.jpg, Hda_obj172.jpg, Fdn_open17.jpg, Bdn_text7.jpg, Fda_A517086.jpg, Mdn_text113.jpg, Mdn_N228075.jpg, Mdn_land159.jpg, Fda_art772.jpg, Fda_A683068.jpg, Hda_obj71.jpg, Fda_art1418.jpg, Bda_art1117.jpg, Bda_room28.jpg, Bdn_for82.jpg, Fda_city14.jpg, Mdn_N295019.jpg, Fdn_land83.jpg, Fdn_bea25.jpg, Bda_obj123.jpg, Fda_art1394.jpg, Hda_obj73.jpg, Bdn_text19.jpg, Fdn_open6.jpg, Bdn_natu156.jpg, Bdn_text3.jpg, Bda_art1263.jpg, Mda_art675.jpg, Mda_par140.jpg, Hda_obj1.jpg, Mdn_N344039.jpg, Fdn_land293.jpg, Bdn_objn102.jpg, Fda_A731012.jpg, Mda_art438.jpg, Bdn_text6.jpg, Hdn_objn34.jpg, Bdn_text20.jpg, Mdn_natu869.jpg, Hdn_objn112.jpg, Fda_urb128.jpg, Bda_art629.jpg, Mda_gre90.jpg, Fdn_land11.jpg, Mdn_N344070.jpg, Fda_A487031.jpg, Fdn_text69.jpg, Mdn_text45.jpg, Fda_city83.jpg, Bda_room133.jpg, Bdn_text4.jpg, Bda_art921.jpg, Bda_art1171.jpg, Hdn_natu805.jpg, Mdn_nat1253.jpg, Mdn_N295009.jpg, Bdn_nat1006.jpg, Bdn_text18.jpg, Hda_obj404.jpg, Mdn_nat164.jpg, Fda_A277094.jpg, Bdn_text106.jpg, Hda_obj176.jpg, Bdn_land872.jpg, Fdn_natu79.jpg, Bdn_nat846.jpg, Bdn_land378.jpg, Mda_gre199.jpg, Hda_obj144.jpg, Mda_gre189.jpg, Mda_urb982.jpg, Fdn_open18.jpg, Mdn_N228078.jpg, Fdn_nat480.jpg, Fda_A487089.jpg, Mda_art1528.jpg, Fda_A244041.jpg, Hdn_objn26.jpg, Hda_obj418.jpg, Fda_A463033.jpg, Fdn_nat10.jpg, Fda_art1529.jpg, Bda_art142.jpg, Mda_archi37.jpg, Fda_A463036.jpg, Mdn_land760.jpg, Fda_A804076.jpg, Mda_archi56.jpg, Bda_room43.jpg, Bda_int46.jpg, Bda_room170.jpg, Hdn_objn32.jpg, Bdn_N44094.jpg, Hda_obj87.jpg, Hda_obj51.jpg, Fda_A805078.jpg, Hdn_objn129.jpg, Hdn_for104.jpg, Hdn_objn27.jpg, Mdn_natu412.jpg, Fdn_nat194.jpg, Hda_obj89.jpg, Fdn_open16.jpg, Mda_urb214.jpg, Bdn_land753.jpg, Fdn_open2.jpg, Fda_art32.jpg, Hda_obj343.jpg, Bdn_for23.jpg, Mda_art1030.jpg, Hda_room421.jpg, Fda_art1535.jpg, Fda_urb794.jpg, Bdn_nat306.jpg, Hdn_objn40.jpg, Mdn_for68.jpg, Bda_urb286.jpg, Bda_enc67.jpg, Hda_obj105.jpg, Hdn_objn38.jpg, Hdn_objn35.jpg, Mdn_natu590.jpg, Fdn_sclos1.jpg, Fda_A673086.jpg, Mdn_for22.jpg, Hda_obj348.jpg, Bdn_text121.jpg, Mdn_N347022.jpg, Mdn_nat256.jpg, Fdn_nat1251.jpg, Mdn_land243.jpg, Bda_gre328.jpg, Mdn_N344026.jpg, Hdn_objn113.jpg, Fda_A244068.jpg, Hda_obj252.jpg, Fda_art1017.jpg, Mdn_text119.jpg, Hda_obj292.jpg, Bda_art1193.jpg, Hdn_objn56.jpg, Fda_obj230.jpg, Mda_archi100.jpg, Hda_obj5.jpg, Fda_urb306.jpg, Hda_obj265.jpg, Fdn_bea2.jpg, Bdn_objn146.jpg, Mdn_N291096.jpg, Bda_int30.jpg, Mdn_N344067.jpg, Hdn_objn23.jpg, Mdn_N328009.jpg, Fda_art709.jpg, Fda_A805045.jpg, Bda_art623.jpg, Fdn_text26.jpg, Hda_obj95.jpg, Hda_int170.jpg, Mda_art517.jpg, \n",
      "Data is of shape : (819200, 256) - done in 128.08s.loading the data called : /tmp/data_cache/2017-05-30_surrogate_data\n",
      "No cache found /tmp/data_cache/2017-05-30_surrogate_dico.pkl: Learning the dictionary with algo = mp \n",
      " Training on 819200 patches... Iteration   0 /   16384 (elapsed time:   6s,  0.0mn)\n",
      "Iteration  1639 /   16384 (elapsed time:  636s,  10.0mn)\n",
      "Iteration  3278 /   16384 (elapsed time:  1264s,  21.0mn)\n",
      "Iteration  4917 /   16384 (elapsed time:  1920s,  32.0mn)\n"
     ]
    }
   ],
   "source": [
    "from shl_scripts.shl_experiments import SHL\n",
    "list_figures  = ['show_dico']#, 'plot_variance',  'plot_variance_histogram',  'time_plot_prob',  'time_plot_kurt',  'time_plot_var']\n",
    "shl = SHL(n_dictionary=n_dictionary, database=database, DEBUG_DOWNSCALE=DEBUG_DOWNSCALE, verbose=verbose, C=C, do_sym=do_sym, nb_quant=nb_quant)\n",
    "data = shl.get_data(matname=matname)\n",
    "dico = shl.learn_dico(matname=matname, list_figures=list_figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Analysis of present coding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "original_coding = shl.coding[:3, :]\n",
    "print(original_coding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate an image from the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Generate a random sparse vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shl_scripts.shl_tools import generate_sparse_vector\n",
    "sparse_vector, rho_vector = generate_sparse_vector(N_image, l0_sparseness, dico.n_dictionary, N_boost=N_boost, K_boost=K_boost, rho_coeff=rho_coeff)\n",
    "print ('Sparse vector = \\n', sparse_vector[i_sample, : ], ' and the respetive rho of each coeff \\n', rho_vector[i_sample, : ])\n",
    "print('List of non-zero coeffficients given by their addresses', np.nonzero(sparse_vector[i_sample, : ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Rho of each non-zero coeffficients given by their addresses', rho_vector[i_sample, np.nonzero(sparse_vector[i_sample, : ]) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Generate an Image as a linear combination of the sparse vector and the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(dico, vector):\n",
    "    image = dico.dictionary.T @ vector.T\n",
    "    return image.T\n",
    "\n",
    "image = generate_images(dico, sparse_vector)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pixels = dico.dictionary.shape[1]\n",
    "n_pixels_sqrt = int(np.sqrt(n_pixels))\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(image[i_sample, :].reshape(n_pixels_sqrt, n_pixels_sqrt), cmap='gray', interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Matching Pursuit Coding of the synthetic image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shl_scripts.shl_encode import mp \n",
    "mp_sparse_code = mp(image, dico.dictionary, l0_sparseness, verbose=True, C=C, do_sym=do_sym)\n",
    "mp_sparse_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sparse vector = ', mp_sparse_code[i_sample, : ])\n",
    "print('List of non-zero coeffficients given by their addresses', np.nonzero(sparse_vector[i_sample, : ]))\n",
    "print('List of non-zero coeffficients given by their addresses', np.nonzero(mp_sparse_code[i_sample, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shl_scripts.shl_tools import plot_scatter_MpVsTrue\n",
    "\n",
    "plot_scatter_MpVsTrue(sparse_vector, mp_sparse_code);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shl_scripts.shl_learn import get_P_cum\n",
    "from shl_scripts.shl_tools import plot_P_cum\n",
    "fig, ax = plot_P_cum(get_P_cum(mp_sparse_code, C=C, do_sym=do_sym))\n",
    "ax.set_ylim(0.9, 1.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vector_, rho_vector_ = generate_sparse_vector(N_image, l0_sparseness, dico.n_dictionary, rho_coeff=.7, N_boost=0, K_boost=1., seed=420, do_sym=do_sym)\n",
    "image_ = generate_images(dico, sparse_vector_)\n",
    "mp_sparse_code_ = mp(image_, dico.dictionary, l0_sparseness, verbose=True, C=C, do_sym=do_sym)\n",
    "plot_scatter_MpVsTrue(sparse_vector_, mp_sparse_code_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_P_cum(get_P_cum(mp_sparse_code_, C=C, do_sym=do_sym))\n",
    "ax.set_ylim(0.9, 1.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Ranks of each non-zero coeffficients given by their addresses', rho_vector[i_sample, np.nonzero(sparse_vector[i_sample, : ]) ] )\n",
    "print ('Ranks of each non-zero coeffficients given by their addresses', rho_vector[i_sample, np.nonzero(mp_sparse_code[i_sample, : ]) ] )\n",
    "from scipy.stats import spearmanr\n",
    "print ('Spearman coeficient ', spearmanr(sparse_vector[:2, : ], mp_sparse_code[:2, : ], axis=1) )\n",
    "spearR = [spearmanr(sparse_vector[i_test, : ], mp_sparse_code[i_test, : ])[0] for i_test in range(N_image) ]\n",
    "print ('Spearman coeficient ', np.mean(spearR), '+/-', np.std(spearR) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearR = [spearmanr(rho_vector[i_test, : ], mp_sparse_code[i_test, : ])[0] for i_test in range(N_image) ]\n",
    "print ('Spearman coeficient ', np.mean(spearR), '+/-', np.std(spearR) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearR = [spearmanr(rho_vector[i_test, np.nonzero(sparse_vector[i_test, : ])], \n",
    "                    mp_sparse_code[i_test, np.nonzero(sparse_vector[i_test, : ]) ])[0] for i_test in range(N_image) ]\n",
    "print ('Spearman coeficient ', np.mean(spearR), '+/-', np.std(spearR) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shl_scripts.shl_tools import plot_proba_histogram\n",
    "from shl_scripts.shl_encode import z_score, prior\n",
    "C = 5\n",
    "n_samples, nb_filter = mp_sparse_code.shape\n",
    "P_cum = np.linspace(0, 1, nb_quant, endpoint=True)[np.newaxis, :] * np.ones((nb_filter, 1))\n",
    "stick = np.arange(dico.n_dictionary)*nb_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rho_sparse_code = z_score(P_cum, prior(mp_sparse_code, C=C), stick)\n",
    "print('Sparse vector = ', mp_sparse_code[i_sample, : ])\n",
    "print('rho_true vector = ', rho_vector[i_sample, : ])\n",
    "print('rho_hat  vector = ', rho_sparse_code[i_sample, : ])\n",
    "spearR = [spearmanr(rho_vector[i_test, : ], rho_sparse_code[i_test, : ])[0] for i_test in range(N_image) ]\n",
    "print ('Spearman coeficient ', np.mean(spearR), '+/-', np.std(spearR) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(spearmanr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_sparse_code[rho_sparse_code==0] = np.nan\n",
    "spearR = [spearmanr(rho_vector[i_test, : ], rho_sparse_code[i_test, : ], nan_policy='omit')[0] for i_test in range(N_image) ]\n",
    "print ('Spearman coeficient ', np.mean(spearR), '+/-', np.std(spearR) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate(P_cum, my_sparse_code):\n",
    "    print('mean Errors per image = ', np.sum(1 - ((np.abs(my_sparse_code)>0)*1) == sparse_vector) / N_image )\n",
    "    fig, ax = plot_proba_histogram(my_sparse_code)\n",
    "    rho_sparse_code = z_score(P_cum, prior(my_sparse_code, C=C), stick)\n",
    "    spearR = [spearmanr(rho_vector[i_test, : ], my_sparse_code[i_test, : ])[0] for i_test in range(N_image) ]\n",
    "    print ('Spearman coeficient ', np.mean(spearR), '+/-', np.std(spearR) )\n",
    "    rho_sparse_code[rho_sparse_code==0] = np.nan\n",
    "    spearR = [spearmanr(rho_vector[i_test, : ], rho_sparse_code[i_test, : ], nan_policy='omit')[0] for i_test in range(N_image) ]\n",
    "    print ('Spearman coeficient ', np.mean(spearR), '+/-', np.std(spearR) )\n",
    "    return np.mean(spearR), np.std(spearR)\n",
    "    \n",
    "evaluate(P_cum, mp_sparse_code)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pcum Coding of the synthetic image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shl_scripts.shl_learn import update_P_cum\n",
    "\n",
    "result = []\n",
    "for i in range(n_step):\n",
    "    Pcum_sparse_code = mp(image, dico.dictionary, l0_sparseness, P_cum=P_cum, C=C, do_sym=do_sym)\n",
    "    P_cum = update_P_cum(P_cum, code=Pcum_sparse_code, eta_homeo=eta_homeo, nb_quant=nb_quant, C=C, do_sym=do_sym, verbose=False)\n",
    "    if i % (n_step//20) == 0:\n",
    "        print('Learning step', i)\n",
    "        result.append([i, evaluate(P_cum, Pcum_sparse_code)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P_cum = np.linspace(0, 1, nb_quant, endpoint=True)[np.newaxis, :] * np.ones((nb_filter, 1))\n",
    "fig, ax = plot_P_cum(P_cum, verbose=False);\n",
    "ax.set_ylim(0.9, 1.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion: plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if do_plots:\n",
    "    figsize = (8, 3)\n",
    "    from shl_scripts.shl_tools import plot_P_cum\n",
    "    #P_cum = np.linspace(0, 1, nb_quant, endpoint=True)[np.newaxis, :] * np.ones((nb_filter, 1))\n",
    "    fig, ax = plot_P_cum(P_cum, verbose=False);\n",
    "    fig.set_size_inches(figsize)\n",
    "    plt.tight_layout()\n",
    "    ax.set_ylim(0.85, 1.01);\n",
    "    fig.savefig('z_score.pdf')\n",
    "\n",
    "\n",
    "    fig, ax = plot_proba_histogram(mp_sparse_code)\n",
    "    fig.set_size_inches(figsize)\n",
    "    plt.tight_layout()\n",
    "    ax.set_xlim(0, shl.n_dictionary)\n",
    "    fig.savefig('PDF_nohomeo.pdf')\n",
    "\n",
    "    fig, ax = plot_proba_histogram(Pcum_sparse_code)\n",
    "    fig.set_size_inches(figsize)\n",
    "    plt.tight_layout()\n",
    "    ax.set_xlim(0, shl.n_dictionary)\n",
    "    fig.savefig('PDF_homeo.pdf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
